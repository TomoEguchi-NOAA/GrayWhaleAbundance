---
title: "R Notebook"
output: html_notebook
---

This notebook describes abundance estimation of gray whales using Durban's WinBUGS code and Ver2.0 data extraction method. Ver1.0 was developed by John Durban and updated by Josh Stewart. I created Ver2.0, which corrected some errors in Ver1.0. In this notebook, the new data from the 2021/2022, 2022/2023, 2023/2024, and 2024/2025 seasons were added to the previous data and run with WinBUGS. 

For 2009/2010 and 2010/2011, there were two stations. The original bugs code uses the same watch lengths for two stations. Actual watch periods, however, were different. So, that needs to be addressed. I will use the input for the previous analysis (Durban or Stewart) in the analysis for the 2023/2024 season. This has been fixed for 2009/2010 and 2010/2011 by re-extracting data from the raw data files in Extract_Data_All_v2.Rmd. For the 2006/2007 and 2007/2008 seasons, however, no raw data files were available. So, the same original input data for WinBUGS were used for all minimum shift durations. 

For now, I used the input list directly out of Durban/Stewart analysis for 2006/2007 and 2007/2008. Input lists for all other years are built from scratch in the data2WinBUGS_input function (found in Granite_Canyon_Counts_fcns.R). 

Need to fix the secondary station data setup. 2024-03-04 This has been fixed in November 2024.

Set up libraries

```{r}
rm(list=ls())
#library(R2jags)
library(abind)
library(R2WinBUGS)
library(tidyverse)

WinBUGS.dir <- paste0(Sys.getenv("HOME"), "/WinBUGS14")

source("Granite_Canyon_Counts_fcns.R")

# data.dir refers to the output directory of Extract_Data_All_v2.Rmd
# years in this function refers to the years for which raw data were available
# and Extract_Data_All_v2.Rmd was run. The 2006/2007 and 2007/2008 data were not
# available. 
# min.dur is the minimum duration of a observation period - this is in the
# file names in data.dir, e.g., min85, min30. 
WinBUGS.input <- data2WinBUGS_input(data.dir = "RData/V2.1_Feb2025",
                                    years = c(2010, 2011, 2015, 2016, 2020, 2022, 2023, 2024, 2025),
                                    min.dur = 30) # one of 10, 30, 85 or any other that was used in Extract_Data_All_v2.Rmd

# WinBUGS.input <- data2WinBUGS_input(data.dir = "RData/V2.1_Nov2024",
#                                     years = c(2010, 2011, 2015, 2016, 2020, 2022, 2023, 2024),
#                                     min.dur = 30)

# Good to run with 10k/6k as a practice run to see if WinBUGS completes computation.
# Then, increase iterations/burnin to 100k/60k. Sometimes... 100k returns unknown errors.
# 85k seems to have no problems. 

# MCMCparams <- list(n.iter = 85000, #200, #
#                    n.thin = 50, #2, #80
#                    n.burnin = 50000, #50, #
#                    n.chains = 5)

MCMCparams <- list(n.iter = 100000, #200, #
                   n.thin = 50, #2, #80
                   n.burnin = 60000, #50, #
                   n.chains = 5)
# 
# This set runs quickly. Good to use this set to see if data and model are correct.
# MCMCparams <- list(n.iter = 200,
#                    n.thin = 2,
#                    n.burnin = 50,
#                    n.chains = 5)
# 
n.samples <- ((MCMCparams$n.iter - MCMCparams$n.burnin)/MCMCparams$n.thin)*MCMCparams$n.chains

Run_Date <- Sys.Date()  
options(scipen = 999)  # to avoid having 1e+05 for 100000
out.file.name <- paste0("RData/WinBUGS_", min(WinBUGS.input$all.years), "to",
                        max(WinBUGS.input$all.years), "_v2_min", WinBUGS.input$min.dur,
                        "_", MCMCparams$n.iter, "_", Run_Date, ".rds")
options(scipen = 0)
```

Set up WinBUGS and run if it hasn't been run today.:

```{r}

parameters <- c("lambda","OBS.RF","OBS.Switch",
                "BF.Switch","BF.Fixed","VS.Switch",
                "VS.Fixed","mean.prob", 
                "Corrected.Est","Raw.Est","z",
                "com","sp","Daily.Est","mean.beta",
                "beta.sigma","beta","beta.sp","b.sp","sd.b.sp")

if (!file.exists(out.file.name)){
 
  #Run time: 
  Start_Time<-Sys.time()
  
  BUGS_out <- bugs(data = WinBUGS.input$data,
                   inits = WinBUGS.input$inits,
                   parameters.to.save = parameters,
                   model.file="GW_Nmix_Orig.bugs",
                   n.chains = MCMCparams$n.chains,
                   n.iter = MCMCparams$n.iter, 
                   n.burnin = MCMCparams$n.burnin, 
                   n.thin = MCMCparams$n.thin,
                   debug = F,
                   bugs.directory = WinBUGS.dir,
                   DIC = FALSE)
  
  # 2023-03-03 (problem solved but leave the comments below for future reference)
  # ERROR: NIL dereference (read). According to the user manual, this error may
  # happen "at compilation in some circumstances when an inappropriate
  # transformation is made, for example an array into a scalar." 
  # (https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/manual14.pdf)
  
  # DIC problems: Surprisingly, sometimes when getting a trap (including one with the very
  # informative title “NIL dereference (read)”), setting the argument DIC = FALSE in the bugs()
  # function has helped. (https://www.mbr-pwrc.usgs.gov/software/kerybook/AppendixA_list_of_WinBUGS_tricks.pdf)
  
  # I only changed the effort (Watch.Length) for this analysis using 30 minutes as the 
  # minimum observation duration. That changed the size of data arrays, which shouldn't be an issue. 
  
  # It turned out a new observer (JSD) was introduced when a shorter minimum was used to filter
  # observation period. "JSD" was only found in 2020 (200109_080043). A strange thing happened for that day.
  # During the 0800 shift, JSD/JWG changed to SJC/JDS on 0900, then the shift continued until 0930. The new
  # cutoff time (30 min) picked up the first (1 hr) and the second (30 min) as separate observation periods.

  # 2024-12-13 Running with 10-min minimum watch duration. Undefined real results error. 
  
  Run_Time <- Sys.time() - Start_Time
  Ver2.results <-list(BUGS.input = WinBUGS.input,
                      BUGS.out = BUGS_out,
                      MCMCparams = MCMCparams,
                      Run_Time = Run_Time,
                      Run_Date = Run_Date,
                      Sys.info = Sys.info())
  
  saveRDS(Ver2.results, file = out.file.name)
  
} else {
  Ver2.results <- readRDS(out.file.name)
}

```

Make some plots:

```{r}

# Extract estimated counts
Daily.Est <- Ver2.results$BUGS.out$sims.list$Daily.Est
sp <- Ver2.results$BUGS.out$sims.list$sp
com <- Ver2.results$BUGS.out$sims.list$com
Corrected.Est <- Ver2.results$BUGS.out$sims.list$Corrected.Est

# Each one of them is (# samples) x (90 days) x (# years)
# To plot them using ggplot's facet, I need to convert
# these into 2D dataframes of statistics (upper and lower 
# CIs, median, etc.)
# Daily.Est.list <- sp.list <- com.list <- vector(mode = "list", 
#                                                 length = dim(Daily.Est)[3])
# 
# Daily.Est.UCIs <- Daily.Est.LCIs <- vector(mode = "list",
#                                            length = dim(Daily.Est)[3])

stats.list <- vector(mode = "list",
                     length = dim(Daily.Est)[3])

for (k in 1:dim(Daily.Est)[3]){
  # Daily.Est.list[[k]] <- Daily.Est[,,k]
  # Daily.Est.UCIs[[k]] <- apply(Daily.Est[,,k],2,quantile,0.975)
  # Daily.Est.LCIs[[k]] <- apply(Daily.Est[,,k],2,quantile,0.275)
  # 
  # sp.list[[k]] <- sp[,,k]
  # com.list[[k]] <- com[,,k]
  
  stats.list[[k]] <- data.frame(Daily.Est.median = apply(Daily.Est[,,k], 2,
                                                         median),
                                Daily.Est.LCL = apply(Daily.Est[,,k], 2,
                                                      quantile,0.275),
                                Daily.Est.UCL = apply(Daily.Est[,,k], 2,
                                                      quantile,0.975),
                                sp.median = apply(exp(sp[,,k]), 2,
                                                  median),
                                sp.LCL = apply(exp(sp[,,k]), 2,
                                               quantile,0.025),
                                sp.UCL = apply(exp(sp[,,k]), 2,
                                               quantile,0.975),
                                com.median = apply(exp(com[,,k]), 2,
                                                   median),
                                com.LCL = apply(exp(com[,,k]), 2,
                                                quantile,0.025),
                                com.UCL = apply(exp(com[,,k]), 2,
                                                quantile,0.975),
                                #total.median = apply(exp(sp[,,k]), 1, sum),
                                days = 1:dim(Daily.Est)[2],
                                year = WinBUGS.input$seasons[k])
}

all.stats <- do.call("rbind", stats.list) %>% group_by(year)


```

Figure out how many were observed per day, which are not stored in WinBUGS input. Then, divide them by watch length to come up with naive estimates of how many were seen per day. 

```{r}

obs.day <- WinBUGS.input$data$day
n.obs.primary <- WinBUGS.input$data$n.com[,1,]
Nhats <- list()
k <- 1
for (k in 1:ncol(obs.day)){
  tmp.day <-  WinBUGS.input$data$day[,k] %>% 
    na.omit() 
  tmp.n <- n.obs.primary[1:(length(tmp.day)-2),k]
  tmp.watch <- WinBUGS.input$data$Watch.Length[1:(length(tmp.day)-2),k] %>% na.omit()
  Nhats[[k]] <- data.frame(day = tmp.day[tmp.day > 1 & tmp.day < 90],
                      n = tmp.n,
                      watch = tmp.watch) %>%
    group_by(day) %>%
    summarize(day = first(day),
              n = sum(n),
              watch = sum(watch),
              Nhat = n/watch,
              year = WinBUGS.input$seasons[k])
  
}

Nhats.df <- do.call("rbind", Nhats) %>% group_by(year)

ggplot(data = all.stats) + 
  geom_line(aes(x = days, y = sp.median),
            color = "darkorange") + 
  geom_ribbon(aes(x = days, 
                  ymin = sp.LCL, 
                  ymax = sp.UCL),
              fill = "orange", 
              alpha = 0.5) +
  geom_line(aes(x = days, y = com.median),
            color = "darkred") +
  geom_ribbon(aes(x = days, 
                  ymin = com.LCL, 
                  ymax = com.UCL),
              fill = "red", 
              alpha = 0.5) +
  geom_point(aes(x = days, y = Daily.Est.median),
             shape = 16, fill = "blue", alpha = 0.3) +
  geom_point(data = Nhats.df,
             aes(x = day, y = Nhat),
             shape = 4, color = "darkgreen", alpha = 0.5) +
  facet_wrap(vars(year)) +
  xlab("Days since December 1") + 
  ylab("Whales per day")

```


```{r}

#Com vs Sp
ggplot(data = all.stats) +
  geom_line(aes(x = days, y = sp.median)) +
  geom_ribbon(aes(x = days, 
                  ymin = sp.LCL, 
                  ymax = sp.UCL),
              fill = "orange", alpha = 0.5) + 
  facet_wrap(vars(year))+
  xlab("Days since December 1") + 
  ylab("Whales per day (spline)")



```


```{r}

ggplot(data = all.stats) +
  geom_line(aes(x = days, y = com.median)) +
  geom_ribbon(aes(x = days, 
                  ymin = com.LCL, 
                  ymax = com.UCL),
              fill = "orange", alpha = 0.5) + 
  facet_wrap(vars(year))+
  xlab("Days since December 1") + 
  ylab("Whales per day (Normal)")

```


```{r}

ggplot(data = all.stats) +
  geom_line(aes(x = days, y = Daily.Est.median)) +
  geom_ribbon(aes(x = days, 
                  ymin = Daily.Est.LCL, 
                  ymax = Daily.Est.UCL),
              fill = "orange", 
              alpha = 0.5) + 
  facet_wrap(vars(year))+
  xlab("Days since December 1") + 
  ylab("Whales per day")


```

Total abundance
```{r}
abundance.df <- data.frame(Season = WinBUGS.input$seasons,
                           total.mean = apply(Corrected.Est,
                                              FUN = mean,
                                              MARGIN = 2),
                           total.CV = apply(Corrected.Est,
                                            FUN = function(x) 100*sqrt(var(x))/mean(x),
                                            MARGIN = 2),
                           total.median = apply(Corrected.Est, 
                                                FUN = median, 
                                                MARGIN = 2),
                           total.LCL = apply(Corrected.Est, 
                                             MARGIN = 2, 
                                             FUN = quantile, 0.025),
                           total.UCL = apply(Corrected.Est, 
                                             MARGIN = 2, 
                                             FUN = quantile, 0.975))


write.csv(abundance.df,
          file = paste0("Data/WinBUGS_abundance_", min(WinBUGS.input$all.years), "to",
                        max(WinBUGS.input$all.years), "_v2_min", WinBUGS.input$min.dur,
                        "_", MCMCparams$n.iter, "_", Run_Date, ".csv"))

ggplot(data = abundance.df) + 
  geom_point(aes(x = Season, y = total.median)) + 
  geom_errorbar(aes(x = Season, ymin = total.LCL, ymax = total.UCL))

#median(apply(exp(sp[,,4]),1,sum))

#write_csv(abundance.df, file = Nhats.filename)

```

```{r}
ggplot(data = abundance.df) + 
  geom_point(aes(x = Season, y = total.mean)) + 
  geom_errorbar(aes(x = Season, ymin = total.LCL, ymax = total.UCL))

#ggsave(filename = "figures/abundance_9yrs.png", device = "png", dpi = 600)
```


<!-- ```{r} -->
<!-- n.obs.primary <- as.matrix(n[,1,]) -->
<!-- n.total <- colSums(n, na.rm = T) -->

<!-- n.df <- data.frame(Season = seasons, -->
<!--                    n = n.total[1,]) -->


<!-- ggplot(data = n.df) + -->
<!--   geom_point(aes(x = Season, y = n)) -->
<!-- ``` -->


<!-- Abundance estimates are quite different from the last year's... bring in the raw data and see if they are the same... -->
<!-- ```{r} -->
<!-- # output from Ver2.0 extraction -->
<!-- # years.2023 <-  years[3:7] #c("2010", "2011", "2015", "2016", "2020", "2022", "2023", "2024") -->
<!-- #  -->
<!-- # min.duration <- 85 -->

<!-- #out.v2 <- lapply(years.2023, FUN = function(x) readRDS(paste0("RData/V2.1_Mar2023/out_", x, -->
<!-- #                                                         "_min", min.duration, "_Tomo_v2.rds"))) -->
<!-- seasons.2023 <- c("2006/2007", "2007/2008", "2009/2010", "2010/2011",  -->
<!--              "2014/2015", "2015/2016", "2019/2020", "2021/2022", -->
<!--              "2022/2023") -->

<!-- BUGS.out.2023 <- read_rds(file = "RData/WinBUGS_9yr_v2_min85.rds") -->
<!-- # Extract estimated counts -->
<!-- Daily.Est.2023 <- BUGS.out.2023$BUGS_out$sims.list$Daily.Est -->
<!-- sp.2023 <- BUGS.out.2023$BUGS_out$sims.list$sp -->
<!-- com.2023 <- BUGS.out.2023$BUGS_out$sims.list$com -->
<!-- Corrected.Est.2023 <- BUGS.out.2023$BUGS_out$sims.list$Corrected.Est -->

<!-- # Each one of them is (# samples) x (90 days) x (# years) -->
<!-- # To plot them using ggplot's facet, I need to convert -->
<!-- # these into 2D dataframes of statistics (upper and lower  -->
<!-- # CIs, median, etc.) -->
<!-- # Daily.Est.list <- sp.list <- com.list <- vector(mode = "list",  -->
<!-- #                                                 length = dim(Daily.Est)[3]) -->
<!-- #  -->
<!-- # Daily.Est.UCIs <- Daily.Est.LCIs <- vector(mode = "list", -->
<!-- #                                            length = dim(Daily.Est)[3]) -->

<!-- stats.list.2023 <- vector(mode = "list", -->
<!--                           length = dim(Daily.Est.2023)[3]) -->

<!-- for (k in 1:dim(Daily.Est.2023)[3]){ -->
<!--   # Daily.Est.list[[k]] <- Daily.Est[,,k] -->
<!--   # Daily.Est.UCIs[[k]] <- apply(Daily.Est[,,k],2,quantile,0.975) -->
<!--   # Daily.Est.LCIs[[k]] <- apply(Daily.Est[,,k],2,quantile,0.275) -->
<!--   #  -->
<!--   # sp.list[[k]] <- sp[,,k] -->
<!--   # com.list[[k]] <- com[,,k] -->

<!--   stats.list.2023[[k]] <- data.frame(Daily.Est.median = apply(Daily.Est.2023[,,k], 2, -->
<!--                                                          median), -->
<!--                                 Daily.Est.LCL = apply(Daily.Est.2023[,,k], 2, -->
<!--                                                       quantile,0.275), -->
<!--                                 Daily.Est.UCL = apply(Daily.Est.2023[,,k], 2, -->
<!--                                                       quantile,0.975), -->
<!--                                 sp.median = apply(exp(sp.2023[,,k]), 2, -->
<!--                                                   median), -->
<!--                                 sp.LCL = apply(exp(sp.2023[,,k]), 2, -->
<!--                                                quantile,0.025), -->
<!--                                 sp.UCL = apply(exp(sp.2023[,,k]), 2, -->
<!--                                                quantile,0.975), -->
<!--                                 com.median = apply(exp(com.2023[,,k]), 2, -->
<!--                                                    median), -->
<!--                                 com.LCL = apply(exp(com.2023[,,k]), 2, -->
<!--                                                 quantile,0.025), -->
<!--                                 com.UCL = apply(exp(com.2023[,,k]), 2, -->
<!--                                                 quantile,0.975), -->
<!--                                 #total.median = apply(exp(sp[,,k]), 1, sum), -->
<!--                                 days = 1:dim(Daily.Est.2023)[2], -->
<!--                                 year = seasons.2023[k]) -->
<!-- } -->

<!-- all.stats.2023 <- do.call("rbind", stats.list.2023) %>% group_by(year) -->
<!-- abundance.df.2023 <- data.frame(Season = seasons.2023, -->
<!--                            total.mean = apply(Corrected.Est.2023, -->
<!--                                               FUN = mean, -->
<!--                                               MARGIN = 2), -->
<!--                            total.CV = apply(Corrected.Est.2023, -->
<!--                                             FUN = function(x) 100*sqrt(var(x))/mean(x), -->
<!--                                             MARGIN = 2), -->
<!--                            total.median = apply(Corrected.Est.2023,  -->
<!--                                                 FUN = median,  -->
<!--                                                 MARGIN = 2), -->
<!--                            total.LCL = apply(Corrected.Est.2023,  -->
<!--                                              MARGIN = 2,  -->
<!--                                              FUN = quantile, 0.025), -->
<!--                            total.UCL = apply(Corrected.Est.2023,  -->
<!--                                              MARGIN = 2,  -->
<!--                                              FUN = quantile, 0.975)) -->

<!-- n.2023 <- BUGS.out.2023$BUGS.data$n -->
<!-- n.obs.primary.2023 <- as.matrix(n.2023[,1,]) -->
<!-- n.total.2023 <- colSums(n.2023, na.rm = T) -->

<!-- n.2023.df <- data.frame(Season = seasons.2023, -->
<!--                    n = n.total.2023[1,]) -->

<!-- ``` -->

<!-- Major differences in observed n for 2009/2010 and 2010/2011 when comparing n.df and n.2023.df. So, something happened for these datasets when data were extracted. Look at the data files. The data extraction for 2009/2010 and 2010/2011 was new for 2024. I used the input data from Durban and Stewart for the analysis in 2023.  -->

<!-- ```{r} -->

<!-- data.0 <- readRDS("RData/2006-2019_GC_Formatted_Data.RDS") -->

<!-- n.original <- data.0$n -->
<!-- years.original <- c(2007, 2008, 2010, 2011, 2015, 2016, 2020) -->
<!-- Seasons.original <- c("2006/2007", "2007/2008", "2009/2010", "2010/2011", "2014/2015", "2015/2016", "2019/2020") -->

<!-- n.original.df <- data.frame(Season = Seasons.original, -->
<!--                             n = colSums(n.original[,1,])) -->


<!-- ``` -->

<!-- It's possible that secondary observations for 2010 and 2011 were added to the primary... -->

<!-- ```{r} -->
<!-- data.2010 <- read_rds(file = "RData/V2.1_Feb2024/out_2010_min85_Tomo_v2.rds") -->



<!-- ``` -->

